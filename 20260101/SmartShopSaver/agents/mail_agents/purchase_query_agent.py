# -*- coding: utf-8 -*-
"""
purchase_query_agent.py (MongoDB ç‰ˆ)
å¾è³‡æ–™åº« shopping_records ä»¥é—œéµå­—æœå°‹ä½¿ç”¨è€…å·²è¨˜éŒ„çš„æ¶ˆè²»ï¼Œä¸¦ç”¨ GPT ç”¢ç”Ÿä¸­æ–‡åˆ†æã€‚
"""

from __future__ import annotations
from typing import List, Dict, Optional, Any
from datetime import datetime, timedelta, timezone
import re
import os
from collections import defaultdict

try:
    from zoneinfo import ZoneInfo
    _TZ = ZoneInfo("Asia/Taipei")
except Exception:
    _TZ = timezone(timedelta(hours=8))


def _call_gpt(prompt: str, max_retries: int = 2, timeout_sec: int = 25) -> Optional[str]:
    """ç°¡æ˜“ GPT å‘¼å«"""
    try:
        import openai
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return None
        
        client = openai.OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model=os.getenv("GPT_MODEL", "gpt-4o-mini"),
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1000,
            temperature=0.7,
            timeout=timeout_sec
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return None


def _search_records_db(
    db: Any,
    user_id: str,
    keyword: str,
    months: int = 12,
    limit: int = 300,
) -> List[Dict]:
    """
    MongoDB ç‰ˆæœ¬ï¼šé—œéµå­—æœå°‹
    """
    start_dt = (datetime.now(_TZ).replace(day=1, hour=0, minute=0, second=0, microsecond=0)
                - timedelta(days=30 * (months - 1)))
    start_s = start_dt.strftime("%Y-%m-%d")
    end_dt = datetime.now(_TZ)
    end_s = end_dt.strftime("%Y-%m-%d")
    
    # MongoDB æ­£å‰‡æœå°‹
    regex_pattern = {"$regex": keyword, "$options": "i"}
    
    query = {
        "user_id": user_id,
        "$or": [
            {"subject": regex_pattern},
            {"vendor": regex_pattern},
            {"description": regex_pattern},
            {"snippet": regex_pattern}
        ]
    }
    
    # å˜—è©¦ä½¿ç”¨ shopping_records é›†åˆ
    collection = getattr(db, 'shopping_records', None)
    if collection is None and hasattr(db, 'db'):
        collection = db.db.shopping_records
    
    if collection is None:
        return []
    
    cursor = collection.find(query).sort("email_date", -1).limit(limit)
    
    rows = []
    for r in cursor:
        d = r.get("email_date", "")
        if hasattr(d, "strftime"):
            d_str = d.strftime("%Y/%m/%d")
        elif isinstance(d, str):
            d_str = d[:10].replace("-", "/")
        else:
            d_str = ""
        
        rows.append({
            "record_id": str(r.get("_id", "")),
            "vendor": r.get("vendor", ""),
            "amount": float(r.get("amount", 0) or 0),
            "category": r.get("category", "å…¶ä»–"),
            "date": d_str,
            "subject": r.get("subject", ""),
            "snippet": r.get("snippet", ""),
        })
    
    return rows


def _gpt_summary(keyword: str, rows: List[Dict]) -> Optional[str]:
    """ç”¨ GPT ç”¢ç”Ÿç¹ä¸­é‡é»æ‘˜è¦"""
    if not rows:
        return f"ğŸ” æ‰¾ä¸åˆ°èˆ‡ã€Œ{keyword}ã€ç›¸é—œçš„å·²è¨˜éŒ„æ¶ˆè²»ï¼ˆè¿‘ 12 å€‹æœˆï¼‰ã€‚"
    
    compact = [
        {
            "date": r["date"],
            "vendor": r["vendor"][:80],
            "amount": r["amount"],
            "category": r["category"],
            "subject": (r["subject"] or "")[:120],
        }
        for r in rows[:200]
    ]
    
    prompt = (
        "ä½ æ˜¯æ¶ˆè²»åˆ†æåŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨è€…åœ¨è³‡æ–™åº«ä¸­ï¼Œ"
        "è¿‘ 12 å€‹æœˆèˆ‡æŸå€‹é—œéµå­—ç›¸é—œçš„ç´€éŒ„ï¼ˆJSON é™£åˆ—ï¼‰ã€‚"
        "è«‹ç”¨ç¹é«”ä¸­æ–‡è¼¸å‡ºæ¢åˆ—é‡é»ï¼š\n"
        "1) ç¬¦åˆç­†æ•¸èˆ‡ç¸½é‡‘é¡ï¼›\n"
        "2) ä¸»è¦å•†å®¶/å¹³å°ï¼ˆæœ€å¤š 5 å€‹ï¼Œä¾é‡‘é¡æˆ–æ¬¡æ•¸æ’åºï¼‰ï¼›\n"
        "3) é¡åˆ¥åˆ†å¸ƒï¼ˆæœ€å¤š 5 é¡ï¼‰ï¼›\n"
        "4) æœ€è¿‘ 3 ç­†é‡é»ï¼ˆæ—¥æœŸï¼å•†å®¶ï¼é‡‘é¡ï¼ä¸»æ—¨ç°¡è¿°ï¼‰ï¼›\n"
        "5) è‹¥è³‡æ–™çœ‹èµ·ä¾†æ˜¯å¸³å–®å½™æ•´æˆ–éå–®ç­†è³¼è²·ï¼Œè«‹è¨»è¨˜ã€å¯èƒ½éå–®ç­†è³¼ç‰©æ†‘è­‰ã€å³å¯ã€‚\n"
        "èªæ°£å‹™å¿…ç²¾ç°¡ã€‚\n\n"
        f"é—œéµå­—: {keyword}\n"
        f"ç´€éŒ„(JSON): {compact}"
    )
    
    return _call_gpt(prompt, max_retries=2, timeout_sec=25)


def _fallback_summary(keyword: str, rows: List[Dict]) -> str:
    """GPT ä¸å¯ç”¨æ™‚çš„ä¿åº•æ‘˜è¦"""
    if not rows:
        return f"ğŸ” æ‰¾ä¸åˆ°èˆ‡ã€Œ{keyword}ã€ç›¸é—œçš„å·²è¨˜éŒ„æ¶ˆè²»ï¼ˆè¿‘ 12 å€‹æœˆï¼‰ã€‚"
    
    total = sum(r["amount"] for r in rows)
    by_vendor = defaultdict(float)
    by_cat = defaultdict(float)
    for r in rows:
        by_vendor[r["vendor"]] += r["amount"]
        by_cat[r["category"]] += r["amount"]
    
    top_vendors = sorted(by_vendor.items(), key=lambda x: (-x[1], x[0]))[:5]
    top_cats = sorted(by_cat.items(), key=lambda x: (-x[1], x[0]))[:5]
    
    lines = [
        f"ğŸ” é—œéµå­—ã€Œ{keyword}ã€çš„æ¶ˆè²»æŸ¥è©¢ï¼ˆè¿‘ 12 å€‹æœˆï¼‰",
        f"å…± {len(rows)} ç­†ï¼Œåˆè¨ˆ NT$ {int(total):,} å…ƒ",
        "",
        "â€¢ ä¸»è¦å•†å®¶ï¼š " + "ã€".join(f"{v}(NT${int(amt):,})" for v, amt in top_vendors) if top_vendors else "â€¢ ä¸»è¦å•†å®¶ï¼šâ€”",
        "â€¢ é¡åˆ¥åˆ†å¸ƒï¼š " + "ã€".join(f"{c}(NT${int(amt):,})" for c, amt in top_cats) if top_cats else "â€¢ é¡åˆ¥åˆ†å¸ƒï¼šâ€”",
        "",
        "æœ€è¿‘ 3 ç­†ï¼š",
    ]
    for r in rows[:3]:
        lines.append(f"â€¢ {r['date']} {r['vendor']} NT$ {int(r['amount']):,}ï½œ{(r['subject'] or '')[:30]}")
    
    return "\n".join(lines)


def query_and_analyze(
    user_id: str,
    keyword: str,
    db: Any = None,
    months: int = 12,
    limit: int = 300,
) -> str:
    """
    ä¸»å…¥å£ï¼šå›å‚³ä¸€æ®µå¯ç›´æ¥ç™¼é€åˆ° LINE çš„æ–‡å­—æ‘˜è¦
    
    Args:
        user_id: ç”¨æˆ¶ ID
        keyword: æœå°‹é—œéµå­—
        db: è³‡æ–™åº«ç®¡ç†å™¨å¯¦ä¾‹ï¼ˆå¯é¸ï¼‰
        months: æœå°‹æœˆæ•¸
        limit: æœ€å¤§ç­†æ•¸
    """
    if db is None:
        from utils.mail_utils.mongodb_adapter import get_db_manager
        db = get_db_manager()
    
    try:
        rows = _search_records_db(db, user_id, keyword, months=months, limit=limit)
    except Exception as e:
        return f"âŒ æŸ¥è©¢è³‡æ–™åº«å¤±æ•—ï¼š{e}"
    
    # å…ˆå˜—è©¦ GPTï¼Œå¤±æ•—å‰‡ç”¨ä¿åº•æ‘˜è¦
    gpt = _gpt_summary(keyword, rows)
    if gpt:
        return gpt
    return _fallback_summary(keyword, rows)
